---
tags:
  - llm
date created: Thursday, January 4th 2024, 23:50:13
date modified: Monday, March 25th 2024, 20:50:12
draft: "true"
---


> [!tip] Quantization methods are developed to lower the barrier in GPU resources in terms of serving LLM.


# Prerequisites


## Float32 Vs Float16

```python
np.float32(2 ** 23)
```

[[#Reference]]

Now take a look at some of the commonly used quantization techniques.

# AWQ


# GPTQ


# Reference


- https://en.wikipedia.org/wiki/Single-precision_floating-point_format
