---
tags:
  - llm
draft: "true"
date: 2024-03-24T15:42:15.1515+08:00
last-modified: 2024-05-01T16:09:52.5252+08:00
---


> [!tip] Quantization methods are developed to lower the barrier in GPU resources in terms of serving LLM.


# Prerequisites


## Float32 Vs Float16

```python
np.float32(2 ** 23)
```

[[#Reference]]

Now take a look at some of the commonly used quantization techniques.

# AWQ


# GPTQ


# Reference


- https://en.wikipedia.org/wiki/Single-precision_floating-point_format
